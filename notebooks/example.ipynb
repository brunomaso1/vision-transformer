{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\"><b> [Titulo principal] </b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "\n",
    "<!-- [![Binder](http://mybinder.org/badge.svg)](https://mybinder.org/) -->\n",
    "[![nbviewer](https://img.shields.io/badge/render-nbviewer-orange?logo=Jupyter)](https://nbviewer.org/)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "/* Limitar la altura de las celdas de salida en html */\n",
    ".jp-OutputArea.jp-Cell-outputArea {\n",
    "    max-height: 500px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üõª <em><font color='MediumSeaGreen'>  Instalaciones: </font></em> üõª\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook utiliza [Poetry](https://python-poetry.org/) para la gesti√≥n de dependencias.\n",
    "Primero instala Poetry siguiendo las instrucciones de su [documentaci√≥n oficial](https://python-poetry.org/docs/#installation).\n",
    "Luego ejecuta el siguiente comando para instalar las dependencias necesarias y activar el entorno virtual:\n",
    "\n",
    "- Bash:\n",
    "\n",
    "```bash\n",
    "poetry install\n",
    "eval $(poetry env activate)\n",
    "```\n",
    "\n",
    "- PowerShell:\n",
    "\n",
    "```powershell\n",
    "poetry install\n",
    "Invoke-Expression (poetry env activate)\n",
    "```\n",
    "\n",
    "> üìù <em><font color='Gray'>Nota:</font></em> Para agregar `pytorch` utilizando Poetry, se utiliza el siguiente comando:\n",
    "> ```bash\n",
    "> # M√°s info: https://github.com/python-poetry/poetry/issues/6409\n",
    "> potery source add --priority explicit pytorch_gpu https://download.pytorch.org/whl/cu128 # Seleccionar la wheel adecuada para tu GPU\n",
    "> poetry add --source pytorch_gpu torch torchvision \n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úã <em><font color='DodgerBlue'>Importaciones:</font></em> ‚úã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recarga autom√°tica de m√≥dulos en Jupyter Notebook\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "# Modulos propios\n",
    "from vision_transformer.dataset import load_huggingface_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîß <em><font color='tomato'>Configuraciones:</font></em> üîß\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo actual: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Establece el dispositivo.\n",
    "print(f\"Dispositivo actual: {DEVICE}\")\n",
    "# torch.set_float32_matmul_precision('highest') # Optimizaci√≥n: Establece la precisi√≥n de las multiplicaciones de matrices de punto flotante de 32 bits en 'm√°s alta'.\n",
    "torch.set_float32_matmul_precision('high') # Optimizaci√≥n: Establece la precisi√≥n de las multiplicaciones de matrices de punto flotante de 32 bits en 'alta'.\n",
    "# torch.set_float32_matmul_precision('medium') # Optimizaci√≥n: Establece la precisi√≥n de las multiplicaciones de matrices de punto flotante de 32 bits en 'media'.\n",
    "# torch.backends.cudnn.benchmark = True # Optimizaci√≥n: Para redes CNN (pero como se usa una capa convolucional, se establece en True)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">‚ú®Datos del proyecto:‚ú®</div>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| Subtitulo       | *Fine-tuning* del modelo [modelo] sobre el dataset [dataset]                                                                       |\n",
    "| --------------- | -------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Descrpci√≥n**  | <small>An√°lisis exploratorio del proceso de *fine-tuning* del [modelo] sobre el [dataset]<br/>- *Tarea:* Clasificaci√≥n<br/>- *Modelo*: [modelo]<br/> - *Dataset*: [dataset] </small>|\n",
    "| **Autor** | <small>[Nombre] ([correo]) </small>                                                                                                 |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla de contenidos\n",
    "1. [Carga de datos](#carga-de-datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga de datos <a name=\"carga-de-datos\"></a>\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-09 12:04:36.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvision_transformer.dataset\u001b[0m:\u001b[36mload_huggingface_dataset\u001b[0m:\u001b[36m422\u001b[0m - \u001b[1mCargando el dataset procesado...\u001b[0m\n",
      "\u001b[32m2025-06-09 12:04:39.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvision_transformer.dataset\u001b[0m:\u001b[36mload_huggingface_dataset\u001b[0m:\u001b[36m434\u001b[0m - \u001b[1mEl dataset contiene m√∫ltiples conjuntos (train, test, val). Cargando todos...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24300/24300 [00:00<00:00, 36038.24files/s]\n",
      "Downloading data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2700/2700 [00:00<00:00, 41761.15files/s]\n",
      "Generating train split: 24300 examples [00:01, 18480.40 examples/s]\n",
      "Generating test split: 2700 examples [00:00, 22516.17 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_huggingface_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
