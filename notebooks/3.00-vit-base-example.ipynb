{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\"><b> Ejemplo de fine-tuning </b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "\n",
    "<!-- [![Binder](http://mybinder.org/badge.svg)](https://mybinder.org/) -->\n",
    "[![nbviewer](https://img.shields.io/badge/render-nbviewer-orange?logo=Jupyter)](https://nbviewer.org/)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "/* Limitar la altura de las celdas de salida en html */\n",
    ".jp-OutputArea.jp-Cell-outputArea {\n",
    "    max-height: 500px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üõª <em><font color='MediumSeaGreen'>  Instalaciones: </font></em> üõª\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook utiliza [Poetry](https://python-poetry.org/) para la gesti√≥n de dependencias.\n",
    "Primero instala Poetry siguiendo las instrucciones de su [documentaci√≥n oficial](https://python-poetry.org/docs/#installation).\n",
    "Luego ejecuta el siguiente comando para instalar las dependencias necesarias y activar el entorno virtual:\n",
    "\n",
    "- Bash:\n",
    "\n",
    "```bash\n",
    "poetry install\n",
    "eval $(poetry env activate)\n",
    "```\n",
    "\n",
    "- PowerShell:\n",
    "\n",
    "```powershell\n",
    "poetry install\n",
    "Invoke-Expression (poetry env activate)\n",
    "```\n",
    "\n",
    "> üìù <em><font color='Gray'>Nota:</font></em> Para agregar `pytorch` utilizando Poetry, se utiliza el siguiente comando:\n",
    "> ```bash\n",
    "> # M√°s info: https://github.com/python-poetry/poetry/issues/6409\n",
    "> poetry source add --priority explicit pytorch_gpu https://download.pytorch.org/whl/cu128 # Seleccionar la wheel adecuada para tu GPU\n",
    "> poetry add --source pytorch_gpu torch torchvision \n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úã <em><font color='DodgerBlue'>Importaciones:</font></em> ‚úã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recarga autom√°tica de m√≥dulos en Jupyter Notebook\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datasets import Dataset\n",
    "from loguru import logger\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Modulos propios\n",
    "from vision_transformer.dataset import load_huggingface_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîß <em><font color='tomato'>Configuraciones:</font></em> üîß\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo actual: cuda\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16 \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Establece el dispositivo.\n",
    "print(f\"Dispositivo actual: {DEVICE}\")\n",
    "# # torch.set_float32_matmul_precision('highest') # Optimizaci√≥n: Establece la precisi√≥n de las multiplicaciones de matrices de punto flotante de 32 bits en 'm√°s alta'.\n",
    "# torch.set_float32_matmul_precision('high') # Optimizaci√≥n: Establece la precisi√≥n de las multiplicaciones de matrices de punto flotante de 32 bits en 'alta'.\n",
    "# # torch.set_float32_matmul_precision('medium') # Optimizaci√≥n: Establece la precisi√≥n de las multiplicaciones de matrices de punto flotante de 32 bits en 'media'.\n",
    "# # torch.backends.cudnn.benchmark = True # Optimizaci√≥n: Para redes CNN (pero como se usa una capa convolucional, se establece en True)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">‚ú®Datos del proyecto:‚ú®</div>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| Subtitulo       | *Fine-tuning* del modelo swimv2 sobre el dataset EuroSAT                                                                       |\n",
    "| --------------- | -------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Descrpci√≥n**  | <small>An√°lisis exploratorio del proceso de *fine-tuning* del swimv2 sobre el EuroSAT<br/>- *Tarea:* `Clasificaci√≥n`<br/>- *Modelo*: `swimv2`<br/> - *Dataset*: `EuroSAT` </small>|\n",
    "| **Autor** | <small>[Nombre] ([correo]) </small>                                                                                                 |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla de contenidos\n",
    "1. [Carga de datos](#carga-de-datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga de datos <a name=\"carga-de-datos\"></a>\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-12 11:34:49.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvision_transformer.dataset\u001b[0m:\u001b[36mload_huggingface_dataset\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1mCargando el dataset procesado...\u001b[0m\n",
      "\u001b[32m2025-06-12 11:34:49.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvision_transformer.dataset\u001b[0m:\u001b[36mload_huggingface_dataset\u001b[0m:\u001b[36m438\u001b[0m - \u001b[1mEl dataset contiene m√∫ltiples conjuntos (train, test, val). Cargando todos...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d847b3f9eb4304960f734bb318f336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/24300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85d7047b8e5425f83316a7480e6fb1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/2700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_huggingface_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 24300\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 2700\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Procesamiento de datos <a name=\"procesamiento-de-datos\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset[\"train\"].features[\"label\"].names\n",
    "id2label = {id: label for id, label in enumerate(dataset[\"train\"].features[\"label\"].names)}\n",
    "label2id = {label: id for id, label in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comentar este bloque de prueba cuando se use todo el dataset.\n",
    "from vision_transformer.config import RANDOM_SEED\n",
    "\n",
    "dataset['train'] = dataset['train'].shuffle(seed=RANDOM_SEED).select(range(100))\n",
    "dataset['test'] = dataset['test'].shuffle(seed=RANDOM_SEED).select(range(80))\n",
    "test_image = dataset['test'][0]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64 at 0x2625BF25480>, 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "checkpoint = \"google/vit-base-patch16-224-in21k\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "\n",
    "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "\n",
    "size = (\n",
    "    image_processor.size[\"shortest_edge\"]\n",
    "    if \"shortest_edge\" in image_processor.size\n",
    "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    ")\n",
    "\n",
    "_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [_transforms(img) for img in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.with_transform(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 0, 'pixel_values': tensor([[[-0.5765, -0.5765, -0.5765,  ...,  0.2471,  0.2471,  0.2471],\n",
      "         [-0.5765, -0.5765, -0.5765,  ...,  0.2471,  0.2471,  0.2471],\n",
      "         [-0.5373, -0.5373, -0.5373,  ...,  0.2471,  0.2471,  0.2471],\n",
      "         ...,\n",
      "         [ 0.7020,  0.7020,  0.7020,  ..., -0.3725, -0.3725, -0.3725],\n",
      "         [ 0.7098,  0.7098,  0.7098,  ..., -0.3804, -0.3804, -0.3804],\n",
      "         [ 0.7098,  0.7098,  0.7098,  ..., -0.3804, -0.3804, -0.3804]],\n",
      "\n",
      "        [[-0.4431, -0.4431, -0.4431,  ...,  0.0196,  0.0196,  0.0196],\n",
      "         [-0.4431, -0.4431, -0.4431,  ...,  0.0196,  0.0196,  0.0196],\n",
      "         [-0.4196, -0.4196, -0.4196,  ...,  0.0196,  0.0196,  0.0196],\n",
      "         ...,\n",
      "         [ 0.4353,  0.4353,  0.4353,  ..., -0.1451, -0.1451, -0.1451],\n",
      "         [ 0.4353,  0.4353,  0.4353,  ..., -0.1451, -0.1451, -0.1451],\n",
      "         [ 0.4353,  0.4353,  0.4353,  ..., -0.1451, -0.1451, -0.1451]],\n",
      "\n",
      "        [[-0.3647, -0.3647, -0.3647,  ..., -0.0275, -0.0275, -0.0275],\n",
      "         [-0.3647, -0.3647, -0.3647,  ..., -0.0275, -0.0275, -0.0275],\n",
      "         [-0.3412, -0.3412, -0.3412,  ..., -0.0275, -0.0275, -0.0275],\n",
      "         ...,\n",
      "         [ 0.2863,  0.2863,  0.2863,  ..., -0.2078, -0.2078, -0.2078],\n",
      "         [ 0.2863,  0.2863,  0.2863,  ..., -0.2078, -0.2078, -0.2078],\n",
      "         [ 0.2863,  0.2863,  0.2863,  ..., -0.2078, -0.2078, -0.2078]]])}\n",
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0])\n",
    "print(dataset['train'][0]['pixel_values'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # IMPORTANTE: Si se est√° en un .py, se debe ejecutar dentro del bloque `if __name__ == \"__main__\":`\n",
    "# # if __name__ == \"__main__\":\n",
    "# #     benchmark_dataloader(...)\n",
    "\n",
    "import multiprocessing\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "from datasets import load_dataset  # solo por referencia, ya lo ten√©s cargado\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "simulation_dataset = copy.deepcopy(dataset['train'])\n",
    "\n",
    "# Asegurarse de que est√© en formato PyTorch\n",
    "simulation_dataset.set_format(type=\"torch\", columns=[\"image\", \"label\"])\n",
    "\n",
    "CPU_COUNT = multiprocessing.cpu_count()\n",
    "\n",
    "def benchmark_dataloader(dataset, batch_size=BATCH_SIZE, cpu_count=CPU_COUNT):\n",
    "    num_workers_list = [i for i in range(0, cpu_count, 2)]  # De 0 a CPU_COUNT en pasos de 2\n",
    "    logger.info(f\"üß™ Benchmark con {CPU_COUNT} CPUs l√≥gicos\")\n",
    "    for num_workers in num_workers_list:\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "        start = time.time()\n",
    "        for _ in tqdm(loader, desc=f\"num_workers={num_workers:>2}\", leave=False):\n",
    "            pass  # Solo iteramos para medir el tiempo\n",
    "        end = time.time()\n",
    "        \n",
    "        logger.info(f\"üîπ num_workers = {num_workers:>2} ‚Üí tiempo = {end - start:.2f} s\")\n",
    "\n",
    "\n",
    "# # Ejecutar benchmark\n",
    "# # benchmark_dataloader(simulation_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback, TrainerCallback\n",
    "# from transformers.integrations import MLflowCallback\n",
    "\n",
    "# mlflowcallback = MLflowCallback(\n",
    "#     tracking_uri=\"http://localhost:5000\",  # Cambia esto si tu servidor MLflow est√° en otro lugar.\n",
    "#     experiment_name=\"vision_transformer_experiment\",\n",
    "#     save_model=False,  # No guardar el modelo autom√°ticamente, se guardar√° manualmente.\n",
    "# )\n",
    "\n",
    "\n",
    "class EmptyCacheCallback(TrainerCallback):\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "callback_list = [\n",
    "    EarlyStoppingCallback(\n",
    "        early_stopping_patience=10\n",
    "    )  # Usar con: metric_for_best_model = \"eval_accuracy\" o \"eval_loss\" en Trainer.\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViTForImageClassification(\n",
      "  (vit): ViTModel(\n",
      "    (embeddings): ViTEmbeddings(\n",
      "      (patch_embeddings): ViTPatchEmbeddings(\n",
      "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (encoder): ViTEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x ViTLayer(\n",
      "          (attention): ViTAttention(\n",
      "            (attention): ViTSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): ViTSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ViTIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ViTOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "from vision_transformer.config import MODELS_DIR\n",
    "\n",
    "# NOTA: Un \"step\" es un \"batch\".\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODELS_DIR / \"swimv2\",  # Directorio de salida para los modelos entrenados.\n",
    "    overwrite_output_dir=True,  # Sobrescribe el directorio de salida si ya existe.\n",
    "    eval_strategy=\"epoch\",  # Estrategia de evaluaci√≥n: eval√∫a al final de cada √©poca.\n",
    "    per_device_train_batch_size=BATCH_SIZE, # Tama√±o del lote por dispositivo durante el entrenamiento. Oportunidad de optimizaci√≥n.\n",
    "    per_device_eval_batch_size=BATCH_SIZE, # Tama√±o del lote por dispositivo durante la evaluaci√≥n. Oportunidad de optimizaci√≥n.\n",
    "    # gradient_accumulation_steps=4,    # Acumulaci√≥n de gradientes: acumula gradientes antes de hacer un optimizer.step() para simular un tama√±o de lote m√°s grande. Por defecto es 1.\n",
    "                                        # Oportunidad de optimizaci√≥n.\n",
    "    # eval_accumulation_steps=4, # Acumulaci√≥n de gradientes durante la evaluaci√≥n: Sin establecer, acumula todas las predicciones antes de calcular las m√©tricas (consume mas memoria). \n",
    "                                 # Oportunidad de optimizaci√≥n.\n",
    "    # eval_delay=10, # Retraso de evaluaci√≥n: espera 10 pasos antes de realizar la primera evaluaci√≥n.\n",
    "    # torch_empty_cache_steps=len(dataset['train']) // BATCH_SIZE   # Pasos para vaciar la cach√© de PyTorch: vac√≠a la cach√© cada vez que se completa un paso de entrenamiento.\n",
    "                                                                    # Tambi√©n se puede utilizar un callback.\n",
    "    learning_rate=5e-5,  # Tasa de aprendizaje: tasa de aprendizaje inicial para el optimizador AdamW | Si se utiliza scheduler, puede ser mayor (por ejemplo, 1e-4, 2e-4 o 1e-3).\n",
    "                         # Oportunidad de optimizaci√≥n.\n",
    "    # weight_decay=0.01,  # Decaimiento del peso: regularizaci√≥n L2 para evitar el sobreajuste (se aplica a todos menos a los bias y capas de normalizaci√≥n).\n",
    "                        # Oportunidad de optimizaci√≥n.\n",
    "    # adam_beta1=0.9, # Beta1 para el optimizador AdamW: primer momento. Oportunidad de optimizaci√≥n.\n",
    "    # adam_beta2=0.999, # Beta2 para el optimizador AdamW: segundo momento. Oportunidad de optimizaci√≥n.\n",
    "    # adam_epsilon=1e-8, # Epsilon para el optimizador AdamW: evita la divisi√≥n por cero. Oportunidad de optimizaci√≥n.\n",
    "    num_train_epochs=5,  # N√∫mero de √©pocas de entrenamiento: n√∫mero total de √©pocas para entrenar el modelo.\n",
    "    # lr_scheduler_type=\"reduce_lr_on_plateau\", # Decaimiento de la tasa de aprendizaje: reduce la tasa de aprendizaje cuando la m√©trica de evaluaci√≥n no mejora. \n",
    "                                                # Se puede user \"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\".\n",
    "                                                # \"cosine_with_restarts\" es √∫til para ciclos de entrenamiento, cuando se estanca en un m√≠nimo local (o suponemos que se estanca).\n",
    "                                                # Oportunidad de optimizaci√≥n.\n",
    "    # lr_scheduler_kwargs={\n",
    "    #     \"factor\": 0.1,\n",
    "    #     \"patience\": 10,\n",
    "    #     \"threshold\": 1e-4,\n",
    "    #     \"min_lr\": 0,\n",
    "    #     \"mode\": \"min\",\n",
    "    #     \"verbose\": True\n",
    "    # }, # Argumentos adicionales para el planificador de tasa de aprendizaje. Oportunidad de optimizaci√≥n.\n",
    "    warmup_ratio=0.1,   # Proporci√≥n de calentamiento: aumenta la tasa de aprendizaje linealmente desde 0 hasta la tasa \n",
    "                          # de aprendizaje inicial durante el porcentaje especificado del total\n",
    "                          # de pasos de entrenamiento (por ejemplo, 0.1 significa que la tasa de aprendizaje se calentar√° durante el 10% de los pasos de entrenamiento. \n",
    "                          # Ej: 10 √©pocas con 100 batches (o sea 1000 pasos), la tasa de aprendizaje se calentar√° durante los primeros 100 pasos (10% de 1000)). \n",
    "                          # NO APLICA PARA \"reduce_lr_on_plateau\" o \"constant\". Oportunidad de optimizaci√≥n.\n",
    "    # log_level=\"info\", # Nivel de registro: establece el nivel de registro para el entrenamiento \n",
    "                        # (puede ser \"debug\", \"info\", \"warning\", \"error\" o \"critical\"). Por defecto es \"passive\"\n",
    "                        # que loguea lo actual de la librer√≠a transformers (\"warning\")\n",
    "    # logging_steps=10,   # Pasos de registro: n√∫mero de pasos entre registros. Si es 10, se registra cada 10 pasos.\n",
    "    save_strategy=\"best\", # Estrategia de guardado: puede ser \"no\", \"epoch\", \"steps\" o \"best\". Si es \"steps\", se guarda cada cierto n√∫mero de pasos definido en save_steps.\n",
    "    save_total_limit=3, # Limite de guardado total: n√∫mero m√°ximo de modelos guardados. Si se supera, se eliminan los m√°s antiguos.\n",
    "    logging_strategy=\"epoch\",  # Estrategia de registro: puede ser \"no\", \"epoch\" o \"steps\". Si es \"steps\", se registra cada cierto n√∫mero de pasos definido en logging_steps.\n",
    "    seed=RANDOM_SEED,  # Semilla para la reproducibilidad: establece una semilla para la generaci√≥n de n√∫meros aleatorios.\n",
    "    # bf16=True,    # Habilita el entrenamiento en punto flotante de 16 bits (FP16): reduce el uso de memoria y acelera el \n",
    "                    # entrenamiento en GPUs compatibles (Ampere o posteriores). Sino utiliza 32.\n",
    "    # fp16=True, # Habilita el entrenamiento en punto flotante de 16 bits (FP16): reduce el uso de memoria y acelera el \n",
    "                 # entrenamiento en GPUs compatibles (Volta o posteriores). Sino utiliza 32.\n",
    "    # tf32=True, # Habilita el entrenamiento en punto flotante de 32 bits (TF32): acelera el entrenamiento en \n",
    "                 # GPUs Ampere o posteriores. Relacionado con matmul de PyTorch.\n",
    "    # dataloader_num_workers=0,  # N√∫mero de trabajadores para el cargador de datos: n√∫mero de procesos que se utilizan para cargar los datos en paralelo. \n",
    "                               # Por defecto 0 (thread principal). NOTA: En notebook, hay que usar 0. En .py, se puede cambiar, pero se debe poner\n",
    "                               # el c√≥digo de entrenamiento dentro de un bloque `if __name__ == \"__main__\":` para evitar problemas de multiproceso.\n",
    "                               # Esto en Windows.\n",
    "    # run_name=\"vision_transformer_experiment\", # Nombre de la ejecuci√≥n: nombre de la ejecuci√≥n para el seguimiento de experimentos (MLflow, WandB, etc.). \n",
    "                                                # Si no se especifica, se usa output_dir.\n",
    "    remove_unused_columns=False,  # Elimina las columnas no utilizadas: si es True, elimina las columnas que no se utilizan en el modelo. \n",
    "                                  # Si es False, conserva todas las columnas.\n",
    "                                  # Para este caso debe ser obligatoriamente False, ya que se usa una columna personalizada \"pixel_values\" para las im√°genes.\n",
    "    load_best_model_at_end=True,  # Carga el mejor modelo al final del entrenamiento: carga el modelo con la mejor m√©trica de evaluaci√≥n al final del entrenamiento.\n",
    "    metric_for_best_model=\"accuracy\",   # M√©trica para el mejor modelo: m√©trica que se utiliza para determinar el mejor modelo. \n",
    "                                        # Debe ser el nombre de una m√©trica que retorne el \"evaluator\".\n",
    "                                        # Se usa en conjunto con `load_best_model_at_end=True`\n",
    "    # optim=\"adamw_torch\",  # Optimizador: optimizador a utilizar. Puede ser \"adamw_torch\", \"adamw_hf\" o \"sgd\". Por defecto es \"adamw_torch\".\n",
    "                            # Lista completa: https://github.com/huggingface/transformers/blob/main/src/transformers/training_args.py#L143\n",
    "    # optim_kwargs={} # Argumentos adicionales para el optimizador: diccionario con argumentos adicionales para el optimizador.\n",
    "    # dataloader_persistent_workers=True,  # Habilita trabajadores persistentes para el cargador de datos: si es True, los trabajadores se mantienen \n",
    "                                         # activos entre √©pocas (consume m√°s memoria RAM). Por defecto es False.\n",
    "    # dataloader_prefetch_factor=2,   # Factor de prefetch para el cargador de datos: n√∫mero de lotes que se prefetchean en segundo plano. \n",
    "                                    # Si es 2, significa que habr√° 2 * num_workers lotes \n",
    "    # auto_find_batch_size=True,  # Encuentra autom√°ticamente el tama√±o de lote: si es True, busca autom√°ticamente el tama√±o de lote m√°s \n",
    "                                # grande que se puede utilizar sin exceder la memoria GPU.\n",
    "                                # Hay que tener accelerate instalado. Por defecto False.\n",
    "    # torch_compile=True, # Optimizaci√≥n: Habilita la compilaci√≥n de PyTorch para acelerar el entrenamiento.\n",
    "    # torch_compile_backend=\"max-autotune\", # Optimizaci√≥n: Utiliza la compilaci√≥n de PyTorch para acelerar el entrenamiento.\n",
    "    # torch_compile_mode=\"default\",\n",
    "    # neftune_noise_alpha=0.1, # Optimizaci√≥n: Ajusta el ruido de Neftune.\n",
    "    # eval_on_start=True,  # Eval√∫a al inicio del entrenamiento: si es True, eval√∫a el modelo al inicio del entrenamiento (prueba que funcione correctamente).\n",
    "    # use_liger_kernel=True # Optimizaci√≥n: Utiliza el kernel Liger para acelerar el entrenamiento.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,    # Modelo a entrenar. Puede ser uno preentrenado o uno personalizado (torch.nn.Module). \n",
    "                    # Si no se especifica, se debe usar `model_init` para inicializar el modelo.\n",
    "    args=training_args, # Argumentos de entrenamiento: TrainingArguments que configuran el entrenamiento.\n",
    "    data_collator=data_collator,    # Data collator: collator que se utiliza para agrupar los datos en lotes a partir de una\n",
    "                                    # lista de elementos de train_dataset o eval_dataset. Por defecto es DefaultDataCollator,\n",
    "                                    # si no se pasa processing_class.\n",
    "    train_dataset=dataset['train'],  # Dataset de entrenamiento: dataset que se utiliza para el entrenamiento.\n",
    "    eval_dataset=dataset['test'],    # Dataset de evaluaci√≥n: dataset que se utiliza para la evaluaci√≥n.\n",
    "    processing_class=image_processor,  # Procesador de im√°genes: procesador que se utiliza para pre-procesar las im√°genes antes de pasarlas al modelo.\n",
    "    # model_init=None,  # Inicializador de modelo: funci√≥n que se utiliza para inicializar el modelo si no se pasa un modelo preentrenado. \n",
    "                        # Cada vez que se llama a `trainer.train()`, se inicializa un nuevo modelo (una nueva instancia). \n",
    "                        # Se suele utilizar para optimizaci√≥n. Puede tener un argumento que contiene un trial de Optuna o \n",
    "                        # Ray Tune, por ejemplo, para optimizar hiperpar√°metros. Esto permite modificar la arquitectura.\n",
    "    # compute_loss_func=None, # Funci√≥n de p√©rdida personalizada: funci√≥n que se utiliza para calcular la p√©rdida durante el entrenamiento.\n",
    "    compute_metrics=compute_metrics,    # Funci√≥n de m√©tricas personalizada: funci√≥n que se utiliza para calcular las m√©tricas durante la evaluaci√≥n.\n",
    "                                        # Debe recibir un objeto `EvalPrediction` y retornar un diccionario con las m√©tricas calculadas.\n",
    "    # callbacks=callback_list,  # Lista de callbacks: lista de callbacks que se ejecutan durante el entrenamiento.\n",
    "    # optimizers=(None, None),  # Optimizador y scheduler: tuplas que contienen el optimizador y el scheduler a utilizar. Por defecto AdamW.\n",
    "    # optimizer_cls_and_kwargs=None,  # Clase y argumentos del optimizador: tupla que contiene la clase del optimizador y un \n",
    "                                    # diccionario con los argumentos a pasar al optimizador. Sobreescribe `optim` \n",
    "                                    # y `optim_kwargs` de `TrainingArguments`.\n",
    "    # preprocess_logits_for_metrics=None,   # Preprocesador de logits para m√©tricas: funci√≥n que se utiliza para preprocesar los logits \n",
    "                                            # antes de calcular las m√©tricas.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-12 11:35:01.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mIniciando entrenamiento del modelo...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:54, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.309000</td>\n",
       "      <td>2.308987</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.309800</td>\n",
       "      <td>2.279263</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.266100</td>\n",
       "      <td>2.255673</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.216300</td>\n",
       "      <td>2.236976</td>\n",
       "      <td>0.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.214400</td>\n",
       "      <td>2.223119</td>\n",
       "      <td>0.362500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-12 11:35:56.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mEntrenamiento finalizado. Guardando el modelo...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\": # NOTA IMPORTANTE: Para cambiar el n√∫mero de workers, se debe hacerlo en un .py y en el bloque `if __name__ == \"__main__\":`\n",
    "# sino explota en Windows. Esto pasa en un notebook por ejemplo. En notebook dejar el n√∫mero de workers en 0.\n",
    "logger.info(\"Iniciando entrenamiento del modelo...\")\n",
    "trainer.train()  # Inicia el entrenamiento del modelo.\n",
    "logger.info(\"Entrenamiento finalizado. Guardando el modelo...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>grad_norm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.3090</td>\n",
       "      <td>0.924251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.308987</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.2201</td>\n",
       "      <td>363.478</td>\n",
       "      <td>4.543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.3098</td>\n",
       "      <td>0.974297</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.279263</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>362.043</td>\n",
       "      <td>4.526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.2661</td>\n",
       "      <td>0.876934</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.255673</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2214</td>\n",
       "      <td>361.399</td>\n",
       "      <td>4.517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.2163</td>\n",
       "      <td>0.892453</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.236976</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>339.855</td>\n",
       "      <td>4.248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.2144</td>\n",
       "      <td>0.881729</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.223119</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>345.309</td>\n",
       "      <td>4.316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.7622</td>\n",
       "      <td>9.13</td>\n",
       "      <td>0.091</td>\n",
       "      <td>3.874877e+16</td>\n",
       "      <td>2.263126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      loss  grad_norm  learning_rate  epoch  step  eval_loss  eval_accuracy  \\\n",
       "0   2.3090   0.924251       0.000000    1.0     1        NaN            NaN   \n",
       "1      NaN        NaN            NaN    1.0     1   2.308987         0.0500   \n",
       "2   2.3098   0.974297       0.000050    2.0     2        NaN            NaN   \n",
       "3      NaN        NaN            NaN    2.0     2   2.279263         0.1500   \n",
       "4   2.2661   0.876934       0.000038    3.0     3        NaN            NaN   \n",
       "5      NaN        NaN            NaN    3.0     3   2.255673         0.2500   \n",
       "6   2.2163   0.892453       0.000025    4.0     4        NaN            NaN   \n",
       "7      NaN        NaN            NaN    4.0     4   2.236976         0.3250   \n",
       "8   2.2144   0.881729       0.000013    5.0     5        NaN            NaN   \n",
       "9      NaN        NaN            NaN    5.0     5   2.223119         0.3625   \n",
       "10     NaN        NaN            NaN    5.0     5        NaN            NaN   \n",
       "\n",
       "    eval_runtime  eval_samples_per_second  eval_steps_per_second  \\\n",
       "0            NaN                      NaN                    NaN   \n",
       "1         0.2201                  363.478                  4.543   \n",
       "2            NaN                      NaN                    NaN   \n",
       "3         0.2210                  362.043                  4.526   \n",
       "4            NaN                      NaN                    NaN   \n",
       "5         0.2214                  361.399                  4.517   \n",
       "6            NaN                      NaN                    NaN   \n",
       "7         0.2354                  339.855                  4.248   \n",
       "8            NaN                      NaN                    NaN   \n",
       "9         0.2317                  345.309                  4.316   \n",
       "10           NaN                      NaN                    NaN   \n",
       "\n",
       "    train_runtime  train_samples_per_second  train_steps_per_second  \\\n",
       "0             NaN                       NaN                     NaN   \n",
       "1             NaN                       NaN                     NaN   \n",
       "2             NaN                       NaN                     NaN   \n",
       "3             NaN                       NaN                     NaN   \n",
       "4             NaN                       NaN                     NaN   \n",
       "5             NaN                       NaN                     NaN   \n",
       "6             NaN                       NaN                     NaN   \n",
       "7             NaN                       NaN                     NaN   \n",
       "8             NaN                       NaN                     NaN   \n",
       "9             NaN                       NaN                     NaN   \n",
       "10        54.7622                      9.13                   0.091   \n",
       "\n",
       "      total_flos  train_loss  \n",
       "0            NaN         NaN  \n",
       "1            NaN         NaN  \n",
       "2            NaN         NaN  \n",
       "3            NaN         NaN  \n",
       "4            NaN         NaN  \n",
       "5            NaN         NaN  \n",
       "6            NaN         NaN  \n",
       "7            NaN         NaN  \n",
       "8            NaN         NaN  \n",
       "9            NaN         NaN  \n",
       "10  3.874877e+16    2.263126  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "history = pd.DataFrame(trainer.state.log_history)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'Forest', 'score': 0.11400282382965088},\n",
       " {'label': 'SeaLake', 'score': 0.10881276428699493},\n",
       " {'label': 'AnnualCrop', 'score': 0.10688897967338562},\n",
       " {'label': 'PermanentCrop', 'score': 0.10486926883459091},\n",
       " {'label': 'River', 'score': 0.10069800168275833}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicci√≥n con pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('image-classification', model=model, image_processor=image_processor, device=DEVICE)\n",
    "classifier(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: Forest (index: 1)\n"
     ]
    }
   ],
   "source": [
    "# Predicci√≥n con Pytorch\n",
    "inputs = image_processor(test_image, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs.to(DEVICE)).logits\n",
    "\n",
    "predicted_label_index = logits.argmax(-1).item()\n",
    "predicted_label = model.config.id2label[predicted_label_index]\n",
    "print(f\"Predicted label: {predicted_label} (index: {predicted_label_index})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
